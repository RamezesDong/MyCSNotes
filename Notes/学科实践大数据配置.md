val jdbcDF = spark.read.format("jdbc").

option("url","jdbc:mysql://localhost:3306/spark?useUnicode=true&characterEncoding=utf-8&useSSL=false").

option("driver","com.mysql.cj.jdbc.Driver").

option("dbtable", "student").

option("user", "root").

option("password", "dhz123ljl").

load()

./bin/spark-shell \ --jars /usr/local/spark/jars/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar \ --driver-class-path /usr/local/spark/jars/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar

import java.util.Properties

import org.apache.spark.sql.types._

import org.apache.spark.sql.Row

 

*//**下面我们设置两条数据表示两个学生信息*

val studentRDD = spark.sparkContext.parallelize(Array("3 Rongcheng M 26","4 Guanhua M 27")).map(_.split(" "))

 

*//**下面要设置模式信息*

val schema = StructType(List(StructField("id",IntegerType,true),StructField("name",StringType,true),StructField("gender", StringType,true),StructField("age", IntegerType, true)))

studentDF.write.mode("append").jdbc("jdbc:mysql://localhost:3306/spark", "spark.student", prop)